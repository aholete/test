<!DOCTYPE html>
<html lang="ja">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>ãƒã‚¹ã‚¯åˆ¤å®šï¼ˆã‚«ãƒ¡ãƒ©é¸æŠå¯¾å¿œï¼‰</title>
  <style>
    body {
      font-family: "Segoe UI", sans-serif;
      background: linear-gradient(180deg, #fdfbfb 0%, #ebedee 100%);
      color: #333;
      text-align: center;
      padding: 30px;
    }

    h1 {
      font-size: 1.8em;
      margin-bottom: 10px;
    }

    button {
      background-color: #4CAF50;
      color: white;
      border: none;
      padding: 12px 24px;
      border-radius: 8px;
      cursor: pointer;
      font-size: 16px;
      margin: 8px;
    }

    button:hover {
      background-color: #45a049;
    }

    #webcam-container {
      margin-top: 25px;
      display: flex;
      justify-content: center;
    }

    video {
      border-radius: 10px;
      background: #000;
      width: 300px;
      height: 300px;
      object-fit: cover;
    }

    #label-container {
      margin-top: 20px;
      font-size: 1.1em;
    }

    footer {
      margin-top: 40px;
      font-size: 0.9em;
      color: #666;
    }
  </style>
</head>
<body>
  <h1>ãƒã‚¹ã‚¯åˆ¤å®šï¼ˆã‚«ãƒ¡ãƒ©é¸æŠå¯¾å¿œï¼‰</h1>

  <button onclick="initCamera('user')">ğŸ¥ ã‚¤ãƒ³ã‚«ãƒ¡ãƒ©</button>
  <button onclick="initCamera('environment')">ğŸ“· ã‚¢ã‚¦ãƒˆã‚«ãƒ¡ãƒ©</button>

  <div id="webcam-container"></div>
  <div id="label-container"></div>

  <footer>
    Powered by <a href="https://sites.google.com/view/incict-design" target="_blank">Baron Fujimoto</a>
  </footer>

  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest"></script>
  <script src="https://cdn.jsdelivr.net/npm/@teachablemachine/image@latest"></script>

  <script>
    const URL = "./my_model/";
    let model, maxPredictions, video, stream;

    async function initCamera(facingMode = "user") {
      // ä»¥å‰ã®ã‚«ãƒ¡ãƒ©ã‚’åœæ­¢
      if (stream) {
        stream.getTracks().forEach(track => track.stop());
      }

      document.getElementById("webcam-container").innerHTML = "";
      document.getElementById("label-container").innerHTML = "";

      // ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
      if (!model) {
        model = await tmImage.load(URL + "model.json", URL + "metadata.json");
        maxPredictions = model.getTotalClasses();
      }

      // ã‚«ãƒ¡ãƒ©é¸æŠ
      const constraints = {
        audio: false,
        video: {
          facingMode: facingMode // "user" or "environment"
        }
      };

      try {
        stream = await navigator.mediaDevices.getUserMedia(constraints);
      } catch (err) {
        alert("ã‚«ãƒ¡ãƒ©ã®ã‚¢ã‚¯ã‚»ã‚¹ã‚’è¨±å¯ã—ã¦ãã ã•ã„ã€‚");
        return;
      }

      // video è¦ç´ ä½œæˆ
      video = document.createElement("video");
      video.width = 300;
      video.height = 300;
      video.autoplay = true;
      video.playsInline = true; // iOSã§å¿…è¦
      video.muted = true;
      video.srcObject = stream;
      document.getElementById("webcam-container").appendChild(video);

      // ãƒ©ãƒ™ãƒ«é ˜åŸŸã‚’åˆæœŸåŒ–
      const labelContainer = document.getElementById("label-container");
      for (let i = 0; i < maxPredictions; i++) {
        labelContainer.appendChild(document.createElement("div"));
      }

      // ãƒ«ãƒ¼ãƒ—é–‹å§‹
      video.addEventListener("loadeddata", () => predictLoop());
    }

    async function predictLoop() {
      if (!video || video.readyState < 2) {
        requestAnimationFrame(predictLoop);
        return;
      }

      const prediction = await model.predict(video);
      const labelContainer = document.getElementById("label-container");

      for (let i = 0; i < maxPredictions; i++) {
        labelContainer.childNodes[i].innerHTML =
          `${prediction[i].className}: ${(prediction[i].probability * 100).toFixed(1)}%`;
      }

      requestAnimationFrame(predictLoop);
    }
  </script>
</body>
</html>
