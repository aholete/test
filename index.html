<!DOCTYPE html>
<html lang="ja">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>マスク判定（カメラ選択対応）</title>
  <style>
    body {
      font-family: "Segoe UI", sans-serif;
      background: linear-gradient(180deg, #fdfbfb 0%, #ebedee 100%);
      color: #333;
      text-align: center;
      padding: 30px;
    }

    h1 {
      font-size: 1.8em;
      margin-bottom: 10px;
    }

    button {
      background-color: #4CAF50;
      color: white;
      border: none;
      padding: 12px 24px;
      border-radius: 8px;
      cursor: pointer;
      font-size: 16px;
      margin: 8px;
    }

    button:hover {
      background-color: #45a049;
    }

    #webcam-container {
      margin-top: 25px;
      display: flex;
      justify-content: center;
    }

    #label-container {
      margin-top: 20px;
      font-size: 1.1em;
    }

    footer {
      margin-top: 40px;
      font-size: 0.9em;
      color: #666;
    }
  </style>
</head>
<body>
  <h1>マスク判定（カメラ選択対応）</h1>

  <button onclick="startCamera('user')">🎥 インカメラで開始</button>
  <button onclick="startCamera('environment')">📷 アウトカメラで開始</button>

  <div id="webcam-container"></div>
  <div id="label-container"></div>

  <footer>
    Powered by <a href="https://sites.google.com/view/incict-design" target="_blank">Baron Fujimoto</a>
  </footer>

  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest/dist/tf.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@teachablemachine/image@latest/dist/teachablemachine-image.min.js"></script>

  <script>
    const URL = "./my_model/";
    let model, webcam, labelContainer, maxPredictions;
    let stream; // 現在のカメラストリーム

    async function startCamera(mode) {
      // 既存カメラ停止
      if (stream) {
        stream.getTracks().forEach(track => track.stop());
        document.getElementById("webcam-container").innerHTML = "";
      }

      // モデル未読み込みならロード
      if (!model) {
        model = await tmImage.load(URL + "model.json", URL + "metadata.json");
        maxPredictions = model.getTotalClasses();
      }

      // 利用可能なカメラ一覧を取得
      const devices = await navigator.mediaDevices.enumerateDevices();
      const videoDevices = devices.filter(device => device.kind === "videoinput");

      // 対応するカメラを選択
      let selectedDeviceId = null;
      if (mode === "environment") {
        // アウトカメラを優先して選択
        const backCam = videoDevices.find(d => d.label.toLowerCase().includes("back") || d.label.toLowerCase().includes("environment"));
        selectedDeviceId = backCam ? backCam.deviceId : videoDevices[0]?.deviceId;
      } else {
        // インカメラ
        const frontCam = videoDevices.find(d => d.label.toLowerCase().includes("front") || d.label.toLowerCase().includes("user"));
        selectedDeviceId = frontCam ? frontCam.deviceId : videoDevices[0]?.deviceId;
      }

      const constraints = {
        video: { deviceId: selectedDeviceId ? { exact: selectedDeviceId } : undefined }
      };

      // カメラ起動
      stream = await navigator.mediaDevices.getUserMedia(constraints);

      const video = document.createElement("video");
      video.width = 300;
      video.height = 300;
      video.autoplay = true;
      video.srcObject = stream;
      document.getElementById("webcam-container").appendChild(video);

      // flip設定（インカメラのみ反転）
      const flip = (mode === "user");
      webcam = new tmImage.Webcam(300, 300, flip);
      await webcam.setup({ video: { deviceId: selectedDeviceId } });
      webcam.webcam = video;
      webcam.canvas = document.createElement("canvas");
      webcam.canvas.width = 300;
      webcam.canvas.height = 300;
      document.getElementById("webcam-container").appendChild(webcam.canvas);

      labelContainer = document.getElementById("label-container");
      labelContainer.innerHTML = "";
      for (let i = 0; i < maxPredictions; i++) {
        labelContainer.appendChild(document.createElement("div"));
      }

      predictLoop();
    }

    async function predictLoop() {
      if (!webcam || !webcam.webcam) return;
      const ctx = webcam.canvas.getContext("2d");
      ctx.drawImage(webcam.webcam, 0, 0, 300, 300);

      const prediction = await model.predict(webcam.canvas);
      for (let i = 0; i < maxPredictions; i++) {
        labelContainer.childNodes[i].innerHTML =
          `${prediction[i].className}: ${(prediction[i].probability * 100).toFixed(1)}%`;
      }
      requestAnimationFrame(predictLoop);
    }
  </script>
</body>
</html>
